---
title:  '\begin{center} Predictive Analytics: Credit Risk Scorecard Application \\ Case Study: Group 15 \\  \end{center}'
author:
  - "Jacob Heye Hilbrands (12229285)"
  - "Mustafa Alsudani (1214099)"
  - "Moritz Renkin (11807211)"
  - "Nils Kl√ºwer (12229263)"
  

abstract: "Estimating credit risk is a fundamental capability in the traditional banking business. The rate of loan defaults has an enormous impact on a banks performance. In order to minimize their default rates, banks can employ predictive models to estimate credit default risks and reject loan offers with increased projected risk based on well-defined policies. One oft-quoted method used for assessing potential loan applications is the credit risk scorecard. The credit risk scorecard model attempts to estimate the probability of a potential debtor repaying their debts in accordance with the terms agreed. As a quantitative tool, it can provide the basis for making the decision whether to grant a loan or not, enabling banks to let data drive their most crucial business decisions. In a formal sense, the credit risk scorecard model is a statistical model which can be fit with historic credit and creditor information and subsequently estimate the creditability of new credit applicants by assigning them a credit score. This paper aims to provide the theoretical foundation of how to build such a scorecard model as well as a technical implementation and case study demonstrating the capability of the devised model."
date: "November, 2022"
output:
  pdf_document:
    toc: yes
    number_sections: TRUE
    citation_package: natbib
bibliography: literature.bib
biblio-style: natdin #humannat
include-before:
  \pagebreak
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

\newpage

# Abstract {.unnumbered}

Estimating credit risk is a fundamental capability in the traditional banking business. The rate of loan defaults has an enormous impact on a banks performance. In order to minimize their default rates, banks can employ predictive models to estimate credit default risks and reject loan offers with increased projected risk based on well-defined policies.

One oft-quoted method used for assessing potential loan applications is the credit risk scorecard. The credit risk scorecard model attempts to estimate the probability of a potential debtor repaying their debts in accordance with the terms agreed. As a quantitative tool, it can provide the basis for making the decision whether to grant a loan or not, enabling banks to let data drive their most crucial business decisions.

In a formal sense, the credit risk scorecard model is a statistical model which can be fit with historic credit and creditor information and subsequently estimate the creditability of new credit applicants by assigning them a credit score. This paper aims to provide the theoretical foundation of how to build such a scorecard model as well as a technical implementation and case study demonstrating the capability of the devised model.
<!--
Giving new customers credit results in two options: approve their loan request or deny their application. The scorecard's function is to support this choice. Consequently, credit scoring is a mechanism used to assess the degree of risk connected to a particular application. This tool consists of a set of statistically significant characteristics that may be used to predictably distinguish between good and negative things. Any sources of information that the lender has access to at the time of the application may be used to choose the scorecard variables.-->



# Introduction

In the form of a score and a likelihood of default, credit scoring models and scorecards estimate the risk that a borrower will not return a loan.

For instance, a credit scorecard may award a borrower points based on the following table for their age and income. As previously noted, a single dependent variable, creditability, was predicted using seven independent variables. As a variable transformation strategy, the Weight-of-Evidence technique was adopted.

Therefore, group binning will be used as an extra transfomration strategy for this project's execution. To increase the model's Gini coefficient of prediction, a seventh independent variable was added, and the binning breaks were modified.

# Predictive Analytics Research Methodology

## Predictor Variable Transformation

The commonly-used method of Weight of Evidence (WOE) is employed to get an estimate on the predictive power of the individual, independent attributes with regards to the credit risk. The WOE approach is used to change each independent variable. This technique analyzes the "strength" of grouping for separating good and bad risk based on the ratio of good applicants to bad applicants at each group level and seeks to establish a monotonic connection between the independent variables and the target variable.


```{=tex}
\begin{align} \label{eq:WOE}
WOE = ln(\frac{Distribution of Goods}{Distribution of Bads})*100
\end{align}
```

The transformation steps can be considered as follow:


1. Divide the data into bins, often 10 or 20 at most.

2. Estimate the percentage of good and bad customers.

3. Take the natural log and use that to calculate the WOE.
    
4. Substitute the estimated WOE values for the original data.


Negative cases take precedence over positive ones if WOE values are negative. Positive cases take precedence over negative ones if WOE values are positive.


This accomplishes the following goals:

- All non-linear correlations are removed.
  
- All variables are scaled automatically to some extent.

- Categorical variables are converted to continuous variables.

- Missing Data may be treated as a simple factor value.

We could create a standalone scorecard that a person could manually fill out with a pen and a printout of all pertinent factors.




The following downsides apply to it:

- Binning always results in information loss.

- Score growth along single variables is not continuous and happens in stages.

- Binning calls for manual editing.

- Comparing logistic regression with classically scaled variables makes calculating variable relevance more difficult.


As an alternative to the transformation based on WOE-values, the variables can also be transformed with some pre-defined bin borders. 

## Logistic Regression Analysis

Logistic Regression (also known as Logit-Model) is a statistical Model that can estimate probability of a certain event happening based on one or more independent variables. Its application is widespread in various statistical methods, especially in classification problems and prediction analyses. Contrary to linear regression, the predicted variable in logistic regression is a Bernoulli variable, i.e. a binary random variable $k$ with:

```{=tex}
\begin{align} \label{eq:bernoulli_var}
k \in \{0,1\}
\end{align}
```
Formally, the logistic regression model estimates probability $p$ of the Bernoulli $k$ being 1, corresponding the the event in question happening. The logistic function defining $p(x)$ takes on the form:

```{=tex}
\begin{align} \label{eq:VaR}
p(k) = \frac{e^{{\beta}_0 + {\beta}_1k}}{1 + e^{{\beta}_0 + {\beta_1}k}} = \frac{1}{1 + e^-({{\beta}_0 + {\beta_1}k})}
\end{align}
```

In the domain of Credit Scoring, logistic regression is one of the most widely used statistical models \cite[p.~19]{bolton2009logistic}, mainly because the are simple and easy to implement, with wide-spread support in programming languages and libraries. Another striking advantage in favor of logistic regression in this domain is the absence of necessary major assumptions for variables used.

## Building Scorecards

Statistical and non-statistical methods can be used to create credit scorecards, respectively. Only statistical techniques, such as contingency tables and linear regression models, were employed. This is because, in the context of credit scoring, one might gain from understanding sample estimators and their characteristics, confidence intervals, and hypothesis testing. This information might be applied to determining the relative weights of various traits, both to confirm the relevance of pertinent factors and eliminate irrelevant ones. Here, describing categorical data and concentrating on logistic regression to build a scorecard are the major considerations.


From the standpoint of credit scoring, the response variable represents the client's quality (good or poor), and explanatory variables is a list of traits that have discriminating power, or, in other words, that significantly influence whether a customer is good or bad. Therefore, a statistical model demonstrates how explanatory factors affect the response variable.

```{=tex}
\begin{align} \label{eq:Score}
Score = \sum_{i=1}^{n} (-(WOE_i * \beta_i + \frac{a}{n})*factor+\frac{offset}{n})
\end{align}
```

The regression coefficients are used to scale a scorecard, which is defined as bringing it into compliance with a specific range of points. The logit-transformed prediction probability of logistic regression models is a linear function of the predictor variable values, making them linear models. As a result, a final scorecard model created in this way has the advantageous property that the final credit score (credit risk) is a linear function of the predictors.

## Forecasting Scorepoints and default Probabilities

<!-- This step is considered when the linear model is complete and the final scorecard is made, which can then be used to predict probabilities and award points. The likelihood that an application with a specific score would be good or bad. In-sample forecasting and out-of-sample forecasting are two different forms of forecasting. -->

As described in the previous sections, the devised scorecard model is based on a logistic regression function. The model can be used to predict the likelihood of a potential debtor defaulting on his/her loan, as well as the resulting scorepoints in the context of our scorecard. Based on the forecasted scorepoints a credit applicant can be categorized as either good or bad. 

On a broader scale, the credit scorecard model, which is initially trained with a sample of historical borrower data, allows a banking institution to discriminate "good" from "bad" credit applicants, thereby making the decision whether a loan offer should be extended or not.


## Forecasting Accuracy Testing

Testing the accuracy of forecasts is critical to any model that is sought to be applied in a real world scenario. In the banking industry, estimating credit risk is directly linked to a banks profitability as credit interest is usually calculated based on the risk of loan defaults. Since loan interest can be assumed to provide the main income stream for traditional banks (in contrast to investment banks), having even a small edge in risk forecasting accuracy can pose a tremendous competitive advantage. Therefore, this section defines the methodology to evaluate the accuracy of the model forecasts.

When working with predictive models, both statistical and machine-learning-based, the available data is usually split into a training and a test sample. This has become the de-facto standard over the last decades (\cite{traintestsplit}). The training sample is used to fit the model decide on potential hyper-parameters while the testing sample is used only on the final configured and fitted model to evaluate its accuracy. The rationale behind this split is to assess how the model performs on data it was not originally trained on.

Before deciding on how to split the data, it is important to determine if there are any hidden patterns in the data. For example, if the data was split based on a certain attribute, like date, this attribute has to be statistically independent to the target variable. Since no such attributes can be trivially found in the source data, the split is performed randomly with 75% being used as the training sample and the rest as the testing sample. 

In general, the forecasting accuracy can be tested with both using the data it was fitted with (in-sample) and using the independent testing sample (out-of-sample). Discrepancies between the in-sample and out-of-sample results could hint at overfitting of the model. In order to ensure the resilience of the trained model in a real-world scenario, the testing sample shall not be considered for any decisions, or fittings regarding the our scorecard model, until the final out-of-sample test.


# Empirical results

In this section the approach and the results of building a Out-of-Sample Gini coefficient maximizing scorecard model with only seven predictor variables are presented step-by-step. The scorecard is built on the "germancredit" data which is included in the "scorecard" library.


## Loading and Preparing the Data

The dataset "germancredit" is used from the library "scorecard". Below the import process is shown. The "germancredit" data has 21 variables int total. Seven predictor variables and a single dependent variable the "creditability" will remain for our scorecard model.

```{r echo=T}
# Importing of library and data
library(scorecard)
data("germancredit")
names(germancredit)
```

The first step of finding relevant predictor variables is done with the "var_filter()" function on the entire dataset. The default limits and rates for iv_limit, missing_rate & identical_rate mentioned below are used. The iv_limit excludes every variables whose information value is lower or equal to 0.02 in respect to our depedent variable "creditability". Through this filtering process 7 predictor variables are already excluded which are not eligible for the scorecard model as they cannot meet the explained criteria. In the "data_f.df" 14 variables are remaining, 13 possible predictor variables and one dependent variable "creditablitity". 

```{r echo=T, results='hide'}
# Filtering of variables with iv_limit >= 0.02, missing_rate <= 0.95 
# and identical_rate <= 0.95
data_f.df = var_filter(germancredit, y="creditability")

```

```{r echo=T, results='markup'}
ncol(data_f.df)
```


## Splitting the Data into Train and Test Samples

The remaining 13 possible predictor variables are split with the split_df function into train and test data with a ratio fo 75% train and 25% test data. Afterwards data_f.list is reformatted to be usable in the later process. The following scorecard model is only trained on the train data. The test data is later used to validate and test the performance of the scorecard model.

```{r echo=T, results='hide'}
# Splitting data into train and test data with ratio 0.75
data_f.list = split_df(data_f.df,"creditability",ratio=c(0.75,0.25))
class(data_f.list)
lapply(data_f.list,class)
lapply(data_f.list, dim)
```

```{r include=FALSE, results='hide'}
# Generation a list for response variable: Dummy variable for defaults
default.list = lapply(data_f.list, function(x) x$creditability)
```

## Weight-Of-Evidence (WOE)-Binning

In the following the WOE-Binning is done with the 'woebin' function. For the 'woebin' function the default 'method="tree"' is used to generate the optimal binning of both numerical and categorical predictor variables. The breaks are generated automatically by the function and are saved in the "breaks.list" file.  


```{r echo=T, results='hide'}
# Binning of train data
# breaks.list is saved and imported seperately
bins.list = woebin(data_f.list$train,
                   "creditability",
                   save_breaks_list = "breaks.list")
```

This breaks.list file needs to be run as well to generate a report on the entire scoreboard model process later on.

```{r include=FALSE, results='hide'}
options(scorecard.bin_close_right = FALSE) 
breaks.list=list(
 status.of.existing.checking.account=c("... < 0 DM%,%0 <= ... < 200 DM", "... >= 200 DM / salary assignments for at least 1 year", "no checking account"), 
 duration.in.month=c("8", "16", "34", "44"), 
 credit.history=c("no credits taken/ all credits paid back duly%,%all credits at this bank paid back duly", "existing credits paid back duly till now", "delay in paying off in the past", "critical account/ other credits existing (not at this bank)"), 
 purpose=c("retraining%,%car (used)%,%radio/television", "furniture/equipment%,%repairs", "car (new)%,%domestic appliances%,%business", "education%,%others"), 
 credit.amount=c("1400", "4000", "5000", "9600"), 
 savings.account.and.bonds=c("... < 100 DM", "100 <= ... < 500 DM", "500 <= ... < 1000 DM%,%... >= 1000 DM%,%unknown/ no savings account"), 
 present.employment.since=c("unemployed%,%... < 1 year", "1 <= ... < 4 years", "4 <= ... < 7 years%,%... >= 7 years"), 
 installment.rate.in.percentage.of.disposable.income=c("2", "3", "4"), 
 other.debtors.or.guarantors=c("none%,%co-applicant", "guarantor"), 
 property=c("real estate", "building society savings agreement/ life insurance", "car or other, not in attribute Savings account/bonds", "unknown / no property"), 
 age.in.years=c("26", "30", "35", "39"), 
 other.installment.plans=c("bank%,%stores", "none"), 
 housing=c("rent", "own", "for free")
 )
```

Below plots of seven predictor variables with the highest information value are shown in descending order. This does not mean that these values are the final seven predictor variables. <!--The full plots of all predictor variables can be viewed in the Appendix. -->

```{r fig.height=1.5, fig.align='center', echo=FALSE}
woebin_plot(bins.list$status.of.existing.checking.account)
woebin_plot(bins.list$credit.history)
woebin_plot(bins.list$duration.in.month)
woebin_plot(bins.list$credit.amount)
woebin_plot(bins.list$purpose)
woebin_plot(bins.list$age.in.years)
woebin_plot(bins.list$savings.account.and.bonds)
```

## Transformation of predictor variables

The train and test data is transformed with the generated information by 'woebin' into WOE-based predictor variables. These can be used later in glm and scorecard building. This is done by using the function 'woebin_ply'.

```{r echo=TRUE, results='hide'}
# WOE-Transformation of train and test data
data_woe.list = lapply(data_f.list,
                       function(x) woebin_ply(x, bins.list))
lapply(data_woe.list, class)
lapply(data_woe.list, dim)
```

In addition, the train and test data can be transformed into Bin-Group (GRP) based predictor variables using the bin borders or breaks. The functionality of building a scorecard with the GRP-Transforamtion is not yet implemented in the package at the current state, but the GRP-Transformation is later used for comparison and validation.

```{r echo=TRUE, results='hide'}
# Bin-Group (GRP) Transformation of train and test data
data_grp.list = lapply(data_f.list, 
                       function(x) woebin_ply(x, bins.list, to = 'bin'))
lapply(data_grp.list, class)
lapply(data_grp.list, dim)
```

## Generalized linear model (glm): Regressing response w.r.t. predictors

In this section, the logistic regression models are built. These models are used to select the seven most significant variables and subsequently to build the scorecard model with the chosen variables.

### Selection of seven variables with Logistic regression w.r.t. WOE-transformed predictors
In order to select the seven most significant variables, a logistic regression is performed on the WOE-transformed predictor variables of the train data. The seven predictor variables which have the lowest significance value, are selected.

```{r echo=TRUE, message=FALSE, warning=FALSE}
data_woe_first_iteration.glm <- glm(creditability ~ .,
                                    family = binomial(),
                                    data = data_woe.list$train)
summary(data_woe_first_iteration.glm)
```

The following seven predictor variables are selected as they have the lowest significance value (<0.01):
\begin{itemize}
\item{status.of.existing.checking.account}
\item{duration.in.month}
\item{credit.history}
\item{purpose}
\item{credit.amount}
\item{savings.account.and.bonds}
\item{age.in.years}
\end{itemize}

### Logistic regression w.r.t. selected WOE-transformed predictors

The logistic regression model with the seven selected WOE-transformed predictor variables is built on the train data and saved in "data_woe_second_iteration.glm".

```{r, echo=TRUE}
data_woe_second_iteration.glm <- glm(creditability ~ 
                                      status.of.existing.checking.account_woe
                                      + duration.in.month_woe
                                      + credit.history_woe
                                      + purpose_woe
                                      + credit.amount_woe
                                      + savings.account.and.bonds_woe
                                      + age.in.years_woe,
                                        family = binomial(),
                                        data = data_woe.list$train)
```

### Logistic regression w.r.t. selected GRP-transformed predictors

The logistic regression model with the seven selected GRP-transformed predictor variables is built on the train data and saved in "data_grp_second_iteration.glm".

```{r, echo=TRUE}
data_grp_second_iteration.glm <- glm(creditability ~ 
                                      status.of.existing.checking.account_bin
                                      + duration.in.month_bin
                                      + credit.history_bin
                                      + purpose_bin
                                      + credit.amount_bin
                                      + savings.account.and.bonds_bin
                                      + age.in.years_bin,
                                     family = binomial(),
                                     data = data_grp.list$train)
```

## Building the scorecard-model

The scorecard is built with the logistic regression model of the seven WOE-transformed variables and is saved in "scorecard_woe_second_iteration.scm". The scorecard contains the baseline points and the points associated with every bin. In the output of the command `scorecard_woe_second_iteration.scm$purpose`, the points for each bin of the "purpose" predictor variable is displayed. When the purpose of a credit is e.g. furniture, equipment or repairs, the credit applicant receives -3 points for this predictor variable.

```{r, echo=TRUE}
scorecard_woe_second_iteration.scm <- scorecard(bins.list,
                                               data_woe_second_iteration.glm)
names(scorecard_woe_second_iteration.scm)
scorecard_woe_second_iteration.scm$purpose
```

The scores for the entire "germancredit" data are calculated and saved in "score_woe_second_iteration.df"

```{r, echo=TRUE}
score_woe_second_iteration.df = scorecard_ply(germancredit,
                                             scorecard_woe_second_iteration.scm,
                                             only_total_score = FALSE)
```

The scores for the splitted "germancredit" data (train and test) are calculated and saved in "score_woe_second_iteration.list".

```{r, echo=TRUE}
score_woe_second_iteration.list <- lapply(data_f.list,
                                         function(x) scorecard_ply(x, 
                                            scorecard_woe_second_iteration.scm))
```

A report can also be generated for this scorecard model which includes information on the dataset, model coefficients, model performance, WOE binning, scorecard, population stability, and gains.

```{r echo=TRUE,results='hide', fig.show='hide'}
# Report of Scoreboard with WOE-transformed predictor variables
y<-"creditability"
x<-c("status.of.existing.checking.account","duration.in.month","credit.history",
      "purpose","credit.amount","savings.account.and.bonds",
      "age.in.years")

report(data_f.list,
       y,
       x,
       breaks.list,
       seed = NULL,
       save_report = "Report_WOE_second_iteration")
```

Building a scorecard with GRP-transformed predictor variables is unfortunately not supported by the "scorecard" library. Therefore, no report can be created as well. Nevertheless, the performance of the logistic model of the GRP-transformed predictor variables is compared with the logistic model of the WOE-transformed predictor variables in the next section.

## Predicted probabilities and scorepoints

With the scorecard of the logistic regressions of both WOE- and GRP-transformed predictors and the WOE-transformed predictor variables, the predicted probabilities and scorepoints can be calculated. The predicted probabilities forecast the probability of default for each applicant in the "germancredit" data. The first predicted probabilities of both transformations are displayed below.

```{r echo=TRUE}
# Predicted probabilties w.r.t. WOE-transformed predictors
predProb_woe.list <- lapply(data_woe.list,
                        function(x) predict(data_woe_second_iteration.glm,
                                            type = 'response',x))
head(predProb_woe.list$train)
```

```{r echo=TRUE}
# Predicted probabilties w.r.t. GRP-transformed predictors
predProb_grp.list <- lapply(data_grp.list,
                            function(x) predict(data_grp_second_iteration.glm,
                                                type = 'response',x))
head(predProb_grp.list$train)
```

The calculated scorepoints of the applicants of the "germancredit" data can only be calculated for WOE-transformed predictor variables because no scorecard could be built for the GRP-transformed predictors.

```{r echo=TRUE}
# Predicted scorepoints w.r.t. WOE-transformed predictors
head(score_woe_second_iteration.list$train)
```

From the report that was created above for the scorecard with WOE-transformed predictor variables, it can be can be seen that the target score is 600 and the target predicted probability is 5,26%. That means, that applicants with a score below 600 and with a predicted probability of default higher than 5,26% are declined. 

## Gini Coefficient In-Sample and Out-of-Sample
Below the prediction power of the proposed predictor variables is validated through the In-Sample and Out-of-Sample testing. The full validation is done with the predicted scores in "score_woe_second_iteration.list" and the function perf_eva. To further validate the scorecard the Gini-Coefficient of "data_woe_second_iteration.glm" and "data_grp_second_iteration.glm" is calculated as well. 

```{r echo=TRUE}
#Scorecard Model second iteration
perf_eva(pred = score_woe_second_iteration.list,
         label = default.list,
         binomial_metric = c("gini","auc","r2", "rmse"),
         show_plot=c("roc","ks"),
         confusion_matrix = TRUE)
```


```{r echo=FALSE, results='hide'}
#WOE-Binning, second iteration GLM with 7 predictor variables  
predProb_woe.list <- lapply(data_woe.list,
                        function(x) predict(data_woe_second_iteration.glm,
                                            type = 'response',
                                            x)
)
perf_woe <-perf_eva(pred = predProb_woe.list,
         label = default.list,
         binomial_metric = c("gini"),
         show_plot=c(),
         confusion_matrix = FALSE)
```

WOE-Binning, second iteration GLM with 7 predictor variables 
```{r echo=FALSE}
#WOE-Binning, second iteration GLM with 7 predictor variables 
print(perf_woe$binomial_metric$train)
print(perf_woe$binomial_metric$test)
```


```{r echo=FALSE, results='hide'}
#GRP-Binning, second iteration GLM with 7 predictor variables
predProb_grp.list <- lapply(data_grp.list,
                            function(x) predict(data_grp_second_iteration.glm,
                                                type = 'response',
                                                x)
)
perf_grp <- perf_eva(pred = predProb_grp.list,
         label = default.list,
         binomial_metric = c("gini"),
         show_plot=c(),
         confusion_matrix = FALSE)
```

GRP-Binning, second iteration GLM with 7 predictor variables 
```{r echo=FALSE}
#GRP-Binning, second iteration GLM with 7 predictor variables 
print(perf_grp$binomial_metric$train)
print(perf_grp$binomial_metric$test)
```
|Method | In-Sample Gini-Coefficient | Out-of-Sample Gini-Coefficient |
 | -------- | -------- | ------- |
|Second iteration Scorecard | 0.6436704 | 0.5348129	 |
|Second iteration WOE-Binning | 0.6444203 | 0.5346227	 |
|Second iteration GRP-Binning | 0.6502033 | 0.5352568 |

As expected the In-Sample Gini-Coefficient is much higher as the OoS-Gin-Coefficient, but still performing well with over 50%. The Out-of-Sample testing represents a real world data set much better than the In-Sample testing.
The differences in the OoS testing are marginal ranging from 0.5346227 (WOE-Binning) to 0.5352568 (GRP-Binning) having only a difference of 0.0006341. As stated by Peussa (2016) the OoS-Gini Coefficient should lie between 10% and 50%, having 53.53% shows that the used approach is working. \cite[p.~24]{peussa2016credit}

# Summary

The main objective of this paper is the conception and implementation of a scorecard prediction model as well as examine the impact of different binning methods on the model performance. The initial data sample consisting of past credit information was split into training and testing samples with both in-sample and out-of-sample Gini-coefficients being calculatated in order to quantify the predictive accuracy of the model. 

The seven most significant attributes have been selected out of the germancredit dataset based on their significance value in the logistic regression models. The scorecard model was then fitted with these attributes. The Gini-coefficients from in-sample and out-of-sample testing indicate a solid predictive accuracy with even the out-of-sample gini-coefficient reaching 53.35%. 

<!--
# Appendix

## Full List of WOE-Binnined predictor variables

Bellow the full list of binned possible predictor varibles.

```{r fig.height=2, fig.align='center', echo=FALSE}
woebin_plot(bins.list)
```
-->




